# ansible-galaxy collection install ansible.posix
# ansible-galaxy collection install community.general
- name: prepare_rhel_machine
  hosts: all
  vars:
    install_epel: false
    install_webmin: false
    install_hyperv: false
    install_cockpit: false
    install_kernel_parameters: true
    install_motd: false
    install_neofetch: false
    install_updates: true
    install_extra_groups: false
    docker_prepare: false
    extra_device: ""
    delay_time: 15
    retries_count: 2
    reboot_server: false
    playbook_version: "20240612"
  become: true
  gather_facts: false
  pre_tasks:
    - name: verify_ansible_meets_version_requirements
      ansible.builtin.assert:
        that: "ansible_version.full is version_compare('2.10', '>=')"
        msg: >
          "You must update Ansible to at least 2.10 to use this version of playbook"
      tags:
        - assert
    - name: run_initial_setup_instead_of_gather_facts
      ansible.builtin.setup:
        gather_timeout: 60
      retries: "{{ retries_count }}"
      delay: "{{ delay_time }}"
      register: setup_status
      until: setup_status is success
      changed_when: false
      tags:
        - assert
    - name: assert_root_partition_has_16_GB_of_free_spacee
      ansible.builtin.assert:
        { that: item.mount == '/' or item.size_available > 17179869184 }
      loop: "{{ ansible_mounts }}"
      ignore_errors: false
      when: item.mount == '/'
      register: freespace
      tags:
        - assert
    - name: fact_release
      ansible.builtin.set_fact:
        release: "{{ ansible_distribution_major_version }}"
      changed_when: false
      ignore_errors: false
  tasks:
    - name: display_initial_values
      ansible.builtin.debug:
        msg:
          - "Ansible package manager        :{{ ansible_pkg_mgr | lower }}"
          - "Extra volume name              :{{ extra_device }}"
          - "Extra volume prepare           :{{ docker_prepare | lower }}"
          - "Install Cockpit                :{{ install_cockpit | lower }}"
          - "Install EPEL                   :{{ install_epel | lower }}"
          - "Install extra groups           :{{ install_extra_groups | lower }}"
          - "Install Hyperv                 :{{ install_hyperv | lower }}"
          - "Install MOTD                   :{{ install_motd | lower }}"
          - "Install Neofetch               :{{ install_neofetch | lower }}"
          - "Install kernel parameters      :{{ install_kernel_parameters | lower }}"
          - "Install updates                :{{ install_updates | lower }}"
          - "Install Webmin                 :{{ install_webmin | lower }}"
          - "Reboot server                  :{{ reboot_server | lower }}"
          - "Playbook version               :{{ playbook_version }}"
    # initial cleaning and refreshing metadata for packages
    - name: Initial GPG Keys update
      ansible.builtin.rpm_key:
        key: "{{ item.url }}"
        state: "{{ item.state | default('present') }}"
      loop: "{{ gpgkey }}"
      retries: "{{ retries_count }}"
      delay: "{{ delay_time }}"
      register: r_initial_gpg_keys
      until: r_initial_gpg_keys is success
      when: gpgkey is defined and gpgkey | length > 0
      failed_when: false
    - name: initial_clean
      ansible.builtin.debug:
        msg: "Starting provision"
      notify:
        - clean-metadata
        - makecache
      changed_when: false
    - name: Flush handlers
      ansible.builtin.meta: flush_handlers
    - name: install_initial_packages
      ansible.builtin.package:
        name: "{{ item }}"
        state: latest
      loop: "{{ initial_packages }}"
      retries: "{{ retries_count }}"
      delay: "{{ delay_time }}"
      register: r_initial_packages
      until: r_initial_packages is success
      when: install_updates or not (item | regex_search('.*release.*'))
      any_errors_fatal: true
      tags:
        - packages
        - base
    # enable epel repo - mandatory for other settings
    - name: install_epel
      ansible.builtin.yum:
        name: "{{ item }}"
        state: latest
        disable_gpg_check: true
      retries: "{{ retries_count }}"
      loop: "{{ epel_package }}"
      delay: "{{ delay_time }}"
      register: r_install_epel
      until: r_install_epel is success
      tags:
        - packages
        - base
      when: install_epel
    # - name: enable_epel
    #   community.general.ini_file:
    #     path: "{{ epel.path }} | default ('/etc/yum.repos.d/epel.repo')"
    #     section: "{{ epel.section }} | default ('epel')"
    #     option: enabled
    #     value: "1"
    #     mode: "0644"
    #   retries: "{{ retries_count }}"
    #   delay: "{{ delay_time }}"
    #   when: r_install_epel is success and install_epel
    #   register: r_enable_epel
    #   until: r_enable_epel is success
    #   tags:
    #     - packages
    #     - base
    # let's install extra yumgroups
    - name: refresh_repos
      ansible.builtin.debug:
        msg: "Refreshing repos"
      notify: makecache
      changed_when: true
    - name: install_extra_groups
      ansible.builtin.package:
        name: "{{ item }}"
        state: present
      loop: "{{ yum_extra_groups }}"
      retries: "{{ retries_count }}"
      delay: "{{ delay_time }}"
      register: r_install_extra_groups
      until: r_install_extra_groups is success
      when: install_extra_groups
    # let's install extra packages
    - name: install_extra_packages
      ansible.builtin.package:
        name: "{{ item }}"
        state: present
      loop: "{{ yum_extra_packages }}"
      retries: "{{ retries_count }}"
      delay: "{{ delay_time }}"
      register: r_install_extra_packages
      until: r_install_extra_packages is success
    # let's install extra_epel_packages
    - name: install_extra_epel_packages
      ansible.builtin.package:
        name: "{{ item }}"
        state: present
      loop: "{{ yum_extra_epel_packages }}"
      retries: "{{ retries_count }}"
      delay: "{{ delay_time }}"
      register: r_install_extra_packages
      until: r_install_extra_packages is success
      when: r_install_epel is success and install_epel
    # set selinux policy
    - name: set_selinux_policy
      ansible.posix.selinux:
        state: "{{ selinux.state }}"
      retries: "{{ retries_count }}"
      delay: "{{ delay_time }}"
      register: r_set_linux_policy
      when: selinux.state is defined
    # start webmin block
    - name: start_webmin_block
      when: install_webmin
      block:
        - name: add_webmin_repository
          ansible.builtin.yum_repository:
            name: Webmin
            description: "{{ item.name }}"
            mirrorlist: "{{ item.mirrorlist }}"
            enabled: "{{ item.enabled }} "
            file: "{{ item.file }}"
            gpgkey: "{{ item.gpgkey }}"
          register: r_webmin_repository
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          loop: "{{ webmin }}"
          until: r_webmin_repository is success
          notify: makecache
        - name: add_webmin_package
          ansible.builtin.package:
            name: webmin
            state: latest
          register: r_webmin_package
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          until: r_webmin_package is success
        - name: start_webmin
          ansible.builtin.systemd:
            name: webmin
            enabled: true
          register: r_start_webmin
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          until: r_start_webmin is success
      rescue:
        - name: log_webmin_installation_failure
          ansible.builtin.debug:
            msg: "Failed to install or start Webmin: {{ ansible_failed_result.msg | default('Unknown error') }}"
        - name: set_webmin_installation_failed
          ansible.builtin.set_fact:
            webmin_installation_failed: true
        - name: fail_webmin_installation
          ansible.builtin.fail:
            msg: "Webmin installation failed after retries. Check logs for details."
          when: set_webmin_installation_failed | default(true)

    - name: start_cockpit_block
      when: install_cockpit is defined and install_cockpit
      block:
        - name: install_cockpit
          ansible.builtin.package:
            name: cockpit
            state: latest
          register: r_install_cockpit_package
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          until: r_install_cockpit_package is success|default(false)
        - name: set_cockpit_service_to_start
          ansible.builtin.systemd:
            name: cockpit.socket
            state: started
            enabled: true
          register: r_start_cockpit
          delay: "{{ delay_time }}"
          retries: "{{ retries_count }}"
          until: r_start_cockpit is success
      rescue:
        - name: log_cockpit_installation_failure
          ansible.builtin.debug:
            msg: "Failed to install or start Cockpit: {{ ansible_failed_result.msg | default('Unknown error') }}"
        - name: set_cockpit_installation_failed
          ansible.builtin.set_fact:
            cockpit_installation_failed: true
        - name: fail_cockpit_installation
          ansible.builtin.fail:
            msg: "Cockpit installation failed after retries. Check logs for details."
          when: cockpit_installation_failed | default(true)
    # start neofetch block - requires changes from script to 'per option' settings
    - name: start_neofetch_block
      when: install_neofetch
      block:
        - name: add_neofetch_repository
          ansible.builtin.get_url:
            url: "{{ item.url }}"
            dest: "{{ item.dest }}"
            mode: "0644"
          register: r_neofetch_repository
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          loop: "{{ neofetch.repository }}"
          until: r_neofetch_repository is success
          notify: makecache
          when: "(ansible_distribution_major_version | int < 8) and (ansible_distribution_major_version is defined)"
        - name: install_nefoetch
          ansible.builtin.package:
            name: "{{ neofetch.package.name }}"
            state: latest
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_install_neofetch_package
          until: r_install_neofetch_package is success
          when: r_neofetch_repository is success
        - name: neofetch_first_run
          ansible.builtin.command: neofetch
          when: r_neofetch_repository is success
          changed_when: false
          #          ignore_errors: true
          any_errors_fatal: false
          failed_when: false
        - name: create_config_folder
          ansible.builtin.file:
            path: /etc/neofetch
            state: directory
            mode: "0655"
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_create_config_folder
          until: r_create_config_folder is success
          when: r_neofetch_repository is success
        - name: copy_config_to_etc
          ansible.builtin.copy:
            src: /root/.config/neofetch/config.conf
            dest: /etc/neofetch/config.conf
            remote_src: true
            mode: "0755"
            force: false
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_copy_neofetch_config
          until: r_copy_neofetch_config is success
          when: r_create_config_folder is success
        - name: check_for_prepare_neofetch
          ansible.builtin.stat:
            path: /tmp/prepare_neofetch.sh
          register: r_check_for_prepare_neofetch
        # download neofetch scripts and files that we didn't create - to be replaced by file content section
        - name: get_extra_files
          ansible.builtin.get_url:
            url: "{{ item.url }}"
            dest: "{{ item.dest }}"
            mode: "{{ item.mode }}"
          loop: "{{ remote_files }}"
          register: r_get_extra_files
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          until: r_get_extra_files is success
          when: (r_check_for_prepare_neofetch is defined) and (not r_check_for_prepare_neofetch.stat.exists)
        # run neofetch script - to be replaced
        - name: run_prepare_neofetch
          ansible.builtin.shell: chmod +x /tmp/prepare_neofetch.sh; sh /tmp/prepare_neofetch.sh
          when: install_neofetch and (r_install_neofetch_package is success and r_install_neofetch_package is defined)
          changed_when: false
      rescue:
        - name: log_neofetch_installation_failure
          ansible.builtin.debug:
            msg: "Failed to install or configure Neofetch: {{ ansible_failed_result.msg | default('Unknown error') }}"
        - name: set_neofetch_installation_failed
          ansible.builtin.set_fact:
            neofetch_installation_failed: true
        - name: fail_neofetch_installation
          ansible.builtin.fail:
            msg: "Neofetch installation failed after retries. Check logs for details."
          when: set_neofetch_installation_failed | default(true)
    - name: start_hyperv_block
      when: install_hyperv
      block:
        - name: install_hyperv
          ansible.builtin.package:
            name: hyperv-daemons
            state: latest
          register: r_install_hyperv_package
          until: r_install_hyperv_package is success
        - name: enable_hyperv_services
          ansible.builtin.systemd:
            name: "{{ item.name }}"
            state: started
            enabled: true
          loop: "{{ hyperv }}"
          when: r_install_hyperv_package is success and r_install_hyperv_package is defined
          register: r_enable_hyperv_services
          until: r_enable_hyperv_services is success
        - name: create_ballooning rule
          ansible.builtin.copy:
            dest: /etc/udev/rules.d/100-balloon.rules
            mode: "0644"
            content: |
              SUBSYSTEM=="memory", ACTION=="add", ATTR{state}="online"
          when: (r_install_hyperv_package is success and r_install_hyperv_package is defined) and (r_enable_hyperv_services is success and r_enable_hyperv_services is defined)
      rescue:
        - name: log_hyperv_installation_failure
          ansible.builtin.debug:
            msg: "Failed to install or configure Hyper-V daemons: {{ ansible_failed_result.msg | default('Unknown error') }}"
        - name: set_hyperv_installation_failed
          ansible.builtin.set_fact:
            hyperv_installation_failed: true
        - name: fail_hyperv_installation
          ansible.builtin.fail:
            msg: "Hyper-V installation failed after retries. Check logs for details."
          when: hyperv_installation_failed | default(true)
    - name: start_extra_device_block
      when: docker_prepare
      block:
        - name: check_for_device_existence
          ansible.builtin.stat:
            path: "/dev/{{ extra_device }}"
          register: r_check_for_extra_device
        - name: partition_docker_volume
          community.general.parted:
            device: "/dev/{{ extra_device }}"
            number: 1
            label: gpt
            part_end: 100%
            state: present
          when: r_check_for_extra_device.stat.exists and r_check_for_extra_device is defined
          register: r_partition_docker_volume
        - name: display_info
          ansible.builtin.debug:
            var: r_partition_docker_volume
        - name: create_docker_filesystem
          community.general.filesystem:
            fstype: ext4
            dev: "/dev/{{ extra_device }}1"
            state: present
            resizefs: true
            opts: -L docker
          register: r_create_docker_filesystem
          when: (r_partition_docker_volume is defined and r_partition_docker_volume is success) and (r_check_for_extra_device.stat.exists and r_check_for_extra_device is defined)
        - name: rerun_setup
          ansible.builtin.setup:
            gather_timeout: 30
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: setup_status
          until: setup_status is success
          changed_when: false
        - name: prepare_docker_folder
          ansible.builtin.file:
            name: /var/lib/docker
            state: directory
            mode: "0644"
          when: (r_create_docker_filesystem is defined and r_create_docker_filesystem is success)
        - name: mount_extra_volume
          ansible.posix.mount:
            path: /var/lib/docker
            src: "UUID={{ ansible_devices[extra_device].partitions[extra_device + '1'].uuid }}"
            fstype: ext4
            opts: defaults
            state: mounted
            boot: true
          when: (ansible_devices[extra_device].partitions[extra_device + '1'].uuid | length > 5) and (r_partition_docker_volume is success and r_partition_docker_volume is defined)
      rescue:
        - name: log_docker_device_preparation_failure
          ansible.builtin.debug:
            msg: "Failed to prepare Docker device {{ extra_device }}: {{ ansible_failed_result.msg | default('Unknown error') }}"
        - name: fail_docker_device_preparation
          ansible.builtin.fail:
            msg: "Docker device preparation failed after retries. Device {{ extra_device }} may be in an inconsistent state. Manual cleanup may be required."
          when: fail_on_docker_device_error | default(true)
    # os related block
    - name: start_os_related_block
      block:
        # set locale:
        - name: set_locale
          ansible.builtin.shell: |
            localectl set-locale LANG={{ locale.language }}
            localectl set-keymap {{ locale.keymap }}
            localectl set-x11-keymap {{ locale.keymap }}
          register: r_set_locale
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          until: r_set_locale is success
          any_errors_fatal: false
          changed_when: false
        # set timezone
        - name: set_timezone
          community.general.timezone:
            name: "{{ timezone }}"
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          any_errors_fatal: false
        # create motd
        - name: create_motd
          ansible.builtin.copy:
            dest: /etc/profile.d/motd.sh
            mode: "0755"
            content: "{{ motd }}"
            force: false
          when: install_motd and (r_install_neofetch_package is success and r_install_neofetch_package is defined)
        - name: update_all_packages
          ansible.builtin.package:
            name: "*"
            state: latest
            update_cache: true
          when: install_updates
          register: r_initial_updates
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          until: r_initial_updates is success
          notify:
            - clean-metadata
            - makecache
      rescue:
        - name: log_os_preparation_failure
          ansible.builtin.debug:
            msg: "Failed to prepare OS {{ ansible_failed_result.msg | default('Unknown error') }}"
        - name: fail_os_preparation
          ansible.builtin.fail:
            msg: "OS preparation failed after retries."
          when: fail_on_os_error | default(true)

    # start firewalld block - danger Will Robinson, quite unstable in case of multiple interfaces
    - name: start_firewalld_block
      block:
        # let's start default profile
        - name: start_firewalld
          ansible.builtin.systemd:
            name: firewalld
            state: started
            enabled: true
          register: r_start_firewalld
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          until: r_start_firewalld is success
        # set default zone
        - name: display_interface_info
          ansible.builtin.debug:
            msg: "Primary network interface is: {{ ansible_default_ipv4.interface }}"
          when: ansible_default_ipv4.interface is defined
        - name: make_default_zone
          ansible.posix.firewalld:
            zone: "{{ firewalld.default_zone }}"
            permanent: true
            immediate: true
            interface: "{{ ansible_default_ipv4.interface }}"
            state: enabled
          when: ansible_default_ipv4.interface is defined
          notify:
            - switch_default_firewalld_zone
            - reload_firewalld
        # default zone SHOULD'N be public zone
        - name: remove_from_public
          ansible.posix.firewalld:
            zone: public
            permanent: true
            immediate: true
            interface: "{{ ansible_default_ipv4.interface }}"
            state: disabled
          when: ansible_default_ipv4.interface is defined
          notify:
            - switch_default_firewalld_zone
            - reload_firewalld
        # respond with REJECT
        - name: make_icmp_block
          ansible.posix.firewalld:
            zone: "{{ firewalld.default_zone }}"
            permanent: true
            immediate: true
            state: enabled
            icmp_block: echo-request
          when: ansible_default_ipv4.interface is defined
          notify:
            - switch_default_firewalld_zone
            - reload_firewalld
        # add rich rules from variables
        - name: add_rich_rules
          ansible.posix.firewalld:
            rich_rule: "{{ item.rule }}"
            zone: "{{ firewalld.default_zone }}"
            immediate: true
            state: enabled
            permanent: true
          loop: "{{ firewalld.rich_rules }}"
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_add_rich_rules
          until: r_add_rich_rules is success
          notify: reload_firewalld
          when: ansible_default_ipv4.interface is defined
        - name: add_webmin_rich_rules
          ansible.posix.firewalld:
            rich_rule: "{{ item.rule }}"
            zone: "{{ firewalld.default_zone }}"
            immediate: true
            state: enabled
            permanent: true
          loop: "{{ firewalld.webmin_rich_rules }}"
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_add_webmin_rich_rules
          until: r_add_webmin_rich_rules is success
          notify: reload_firewalld
          when: ansible_default_ipv4.interface is defined and install_webmin
        - name: add_cockpit_rich_rules
          ansible.posix.firewalld:
            rich_rule: "{{ item.rule }}"
            zone: "{{ firewalld.default_zone }}"
            immediate: true
            state: enabled
            permanent: true
          loop: "{{ firewalld.cockpit_rich_rules }}"
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_add_cockpit_rich_rules
          until: r_add_cockpit_rich_rules is success
          notify: reload_firewalld
          when: ansible_default_ipv4.interface is defined and install_cockpit
        # remove services which overlaps with rich rules
        - name: remove_redundand_services
          ansible.posix.firewalld:
            service: "{{ item }}"
            zone: "{{ firewalld.default_zone }}"
            permanent: true
            state: disabled
            immediate: true
          loop: "{{ firewalld.services_remove }}"
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_remove_redundand_services
          until: r_remove_redundand_services is success
          notify: reload_firewalld
          when: ansible_default_ipv4.interface is defined
      rescue:
        - name: log_firewalld_preparation_failure
          ansible.builtin.debug:
            msg: "Failed to prepare Firewalld {{ ansible_failed_result.msg | default('Unknown error') }}"
        - name: fail_firewalld_preparation
          ansible.builtin.fail:
            msg: "Firewalld preparation failed after retries."
          when: fail_on_firewalld_error | default(true)

      # set kernel parameters
    - name: set kernel parameters
      when: (install_kernel_parameters is defined and install_kernel_parameters)
      block:
        # install grubby parameters
        - name: get_info_from_grubby
          ansible.builtin.command: grubby --info=ALL
          register: r_grubby_info
          any_errors_fatal: false
          failed_when: false
          changed_when: false
          until: r_grubby_info is success
          when: (install_kernel_parameters is defined and install_kernel_parameters)
        - name: update_grub_kernel_options_for_all_machines
          ansible.builtin.command: "grubby --args {{ item.key }}={{ item.value }} --update-kernel=ALL"
          when: (item.key ~ "=" ~ item.value not in r_grubby_info.stdout) and (item.state is defined and item.state == "present")
          loop: "{{ kernel_parameters }}"
          changed_when: false
          failed_when: false
        - name: remove_grub_kernel_options_for_all_machines
          ansible.builtin.command: "grubby --remove-args {{ item.key }}={{ item.value }} --update-kernel=ALL"
          when: (item.key ~ "=" ~ item.value in r_grubby_info.stdout) and (item.state is defined and item.state == "absent")
          loop: "{{ kernel_parameters }}"
          changed_when: false
          failed_when: false
        - name: get_info_from_grubby
          ansible.builtin.command: grubby --info=ALL
          register: r_grubby_info
          any_errors_fatal: false
          failed_when: false
          changed_when: false
          until: r_grubby_info is success
      rescue:
        - name: log_kernel_preparation_failure
          ansible.builtin.debug:
            msg: "Failed to prepare kernel {{ ansible_failed_result.msg | default('Unknown error') }}"
        - name: fail_kernel_preparation
          ansible.builtin.fail:
            msg: "Kernel preparation failed after retries."
          when: fail_on_kernel_error | default(true)

    # last touch and cleaning block
    - name: last_touch_and_cleaning_block
      block:
        - name: get_info_about_services
          ansible.builtin.service_facts:
          register: r_service_status
        # services are required
        - name: make_sure_services_are_running
          ansible.builtin.systemd:
            name: "{{ item.name }}"
            state: "{{ item.state }}"
            enabled: "{{ item.enabled }}"
          loop: "{{ services }}"
          register: r_make_sure_services_are_running
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          ignore_errors: true
          any_errors_fatal: false
          until: r_make_sure_services_are_running is success
        - name: change_sshd_dns_settings
          ansible.builtin.lineinfile:
            path: /etc/ssh/sshd_config
            regexp: "UseDNS"
            line: "UseDNS no"
            backrefs: true
            state: present
        # required sysctl entries
        - name: make_sure_sysctl_entries
          ansible.posix.sysctl:
            name: "{{ item.key }}"
            value: "{{ item.value }}"
            state: "{{ item.state }}"
            sysctl_file: /etc/sysctl.d/90_packer_bootstrap.conf
          loop: "{{ sysctl }}"
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_make_sure_sysctl_entries
          until: r_make_sure_sysctl_entries is success
        # start for tuned
        - name: check_if_machine_is_virtual
          ansible.builtin.set_fact:
            machine_type: "{{ ansible_virtualization_role }}"
          when: ansible_virtualization_role is defined
        - name: display_machine_type
          ansible.builtin.debug:
            msg: "Machine type is: {{ machine_type }}"
          when: ansible_virtualization_role is defined
        - name: set_tuned_for_baremetal
          ansible.builtin.shell: tuned-adm profile {{ tuned_profile }}
          args:
            warn: false
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_set_tuned
          until: r_set_tuned is success
          when: machine_type != "guest" and machine_type is defined
          changed_when: false
        - name: Enable synchronize system clock
          ansible.builtin.command: timedatectl set-ntp true
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_set_ntp
          until: r_set_ntp is success
          failed_when: false
          changed_when: false
        - name: restart_chronyd_service
          ansible.builtin.systemd:
            name: chronyd
            state: restarted
            enabled: true
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          register: r_restart_chronyd
          until: r_restart_chronyd is success
          changed_when: false
        - name: update_rkhunter
          ansible.builtin.command: rkhunter --propupd
          failed_when: false
          any_errors_fatal: false
          changed_when: false

        # cleanup kernels in post 8 releases
        - name: cleanup_kernels_post_8
          ansible.builtin.shell: "dnf -y remove --oldinstallonly --setopt installonly_limit=2 kernel|| true"
          register: r_cleanup_kernels_post_8
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          until: r_cleanup_kernels_post_8 is success
          when: release is defined and release | int > 7
          changed_when: false
          ignore_errors: true
          any_errors_fatal: false
        # cleanup kernels in pre 8 releases
        - name: cleanup_kernels_7
          ansible.builtin.command: "package-cleanup --oldkernels --count=2 -y -v"
          register: r_cleanup_kernels_7
          retries: "{{ retries_count }}"
          delay: "{{ delay_time }}"
          until: r_cleanup_kernels_7 is success
          when: release is defined and release | int < 8
          changed_when: false
          ignore_errors: true
          any_errors_fatal: false
        # create stampfile
        - name: create_stampfile
          ansible.builtin.copy:
            dest: "/etc/packerinfo"
            mode: "0644"
            content: |
              { "creationDate": "{{ ansible_date_time.date }}" }
        # let's clean logs and leftovers
        - name: cleaning_stuff
          ansible.builtin.shell: |
            truncate -s 0 /var/log/*
            truncate -s 0 -c /var/log/**/*
            find /var/log -type f -name \"*.[0-99].gz\" -exec rm {} +
            rm -rfv /etc/ansible/*
            rm -rfv /var/log/anaconda/*
            rm -rfv /var/cache/libvirt/*
            rm -rfv /var/cache/powertop/*
            rm -rfv /var/crash/*
            rm -rfv /var/tmp/*
          any_errors_fatal: false
          failed_when: false
          changed_when: false
          notify:
            - clean-metadata
      rescue:
        - name: log_misc_failure
          ansible.builtin.debug:
            msg: "Failed to prepare misc {{ ansible_failed_result.msg | default('Unknown error') }}"
        - name: fail_misc_preparation
          ansible.builtin.fail:
            msg: "Misc preparation failed after retries."
          when: fail_on_misc_error | default(true)

    - name: reboot_server
      ansible.builtin.reboot:
        pre_reboot_delay: 20
        post_reboot_delay: 20
        reboot_timeout: 1200
      when: reboot_server
    # end play
    - name: end_host
      ansible.builtin.meta: end_host
  handlers:
    - name: makecache
      ansible.builtin.shell: "{{ ansible_pkg_mgr }} makecache -y"
      args:
        warn: false
      changed_when: false
    - name: clean-metadata
      ansible.builtin.shell: "{{ ansible_pkg_mgr }} clean all -y"
      args:
        warn: false
      changed_when: false
    - name: switch_default_firewalld_zone
      ansible.builtin.shell: "firewall-cmd --set-default-zone={{ firewalld.default_zone }}"
      args:
        warn: false
      changed_when: false
      when: (firewalld.default_zone is defined) and (firewalld.default_zone | length > 0)
    - name: reload_firewalld
      ansible.builtin.shell: "firewall-cmd --reload"
      args:
        warn: false
      changed_when: false
